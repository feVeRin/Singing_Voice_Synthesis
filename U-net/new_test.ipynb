{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import Audio\n",
    "import IPython\n",
    "\n",
    "import soundfile as sf\n",
    "import torch\n",
    "import torchaudio\n",
    "import librosa\n",
    "\n",
    "from pathlib import Path\n",
    "import museval\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from mir_eval.separation import bss_eval_sources\n",
    "import scipy.signal\n",
    "import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "N_PART = 4\n",
    "N_FFT = 2047\n",
    "SAMPLING_RATE = 22050\n",
    "\n",
    "from u_net import UNet, padding\n",
    "\n",
    "input_wav = '/userHome/userhome2/dahyun/voice/Singing_Voice_Synthesis/data/convertMUSDB/test/Al James - Schoolboy Facination.stem.wav'\n",
    "output_dir = '/userHome/userhome2/dahyun/voice/Singing_Voice_Synthesis/U-net/new_unet/separates/source'\n",
    "model_path = '/userHome/userhome2/dahyun/voice/Singing_Voice_Synthesis/U-net/new_unet/outputs/model-475.pth'\n",
    "\n",
    "cuda_check = torch.cuda.is_available()\n",
    "device = torch.device(f'cuda:1' if cuda_check else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "def median_nan(a):\n",
    "    return np.median(a[~np.isnan(a)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate(input_wav):\n",
    "    with torch.no_grad():\n",
    "        sound, sr = torchaudio.load(input_wav)\n",
    "        if sr > SAMPLING_RATE:\n",
    "            sound = torchaudio.functional.resample(sound, orig_freq=44100, new_freq=SAMPLING_RATE) # sampling rate fixing\n",
    "        sound = sound[[0], :].to(device)\n",
    "\n",
    "        window = torch.hann_window(N_FFT, device=device)\n",
    "\n",
    "        # Convert it to power spectrogram, and pad it to make the number of\n",
    "        # time frames to a multiple of 64 to be fed into U-NET\n",
    "        sound_stft = torch.stft(sound, N_FFT, window=window, return_complex=False)\n",
    "        sound_spec = sound_stft.pow(2).sum(-1).sqrt()\n",
    "        sound_spec, (left, right) = padding(sound_spec)\n",
    "\n",
    "        # Load the model\n",
    "        model = UNet(N_PART)\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "\n",
    "        right = sound_spec.size(2) - right\n",
    "        mask = model(sound_spec).squeeze(0)[:, :, left:right]\n",
    "        separated = mask.unsqueeze(3) * sound_stft\n",
    "        \n",
    "        #print(separated.type(torch.complex64)[:,:,:,0].shape)\n",
    "        #separated = librosa.istft(separated.cpu().numpy(), n_fft=N_FFT, window='hann', length=sound.size(-1))\n",
    "        # istft requires complex tensor // forced dtype transform\n",
    "        separated = torch.istft(separated.type(torch.complex64)[:,:,:,0], N_FFT, window=window, length=sound.size(-1))\n",
    "        separated = separated.cpu().numpy()\n",
    "    \n",
    "    return separated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [06:25<00:00,  7.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3391093366341078, 1.2319471705340366, inf, -0.6625178621691593]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tracks = []\n",
    "result = pd.DataFrame(columns=['track','SDR','ISR', 'SIR', 'SAR'])\n",
    "\n",
    "p = Path('/userHome/userhome2/dahyun/voice/Singing_Voice_Synthesis/data/MUSDB', 'test')\n",
    "reference_dir = Path('/userHome/userhome2/dahyun/voice/Singing_Voice_Synthesis/data/MUSDB', 'test')\n",
    "for track_path in tqdm.tqdm(p.iterdir(), disable=True):\n",
    "    tracks.append(track_path)\n",
    "\n",
    "for track in tqdm.tqdm(tracks):\n",
    "    # seaparate\n",
    "    input_file = str(Path(track, 'mixture.wav'))\n",
    "    separated = separate(input_file)\n",
    "\n",
    "    output_path = Path('/userHome/userhome2/dahyun/voice/Singing_Voice_Synthesis/U-net/new_unet/separates', 'estimates', Path(input_file).parent.name)\n",
    "    output_path.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    # save to wav\n",
    "    for i in range(4):\n",
    "        sf.write(str(output_path) + '/source' + str(i)+ '.wav', separated.T[:,i], SAMPLING_RATE)\n",
    "\n",
    "    # evaluation\n",
    "    estdir = output_path\n",
    "    refdir = Path(reference_dir, estdir.name)\n",
    "    if refdir.exists():\n",
    "        ref, sr = sf.read(str(Path(refdir, 'vocals' + '.wav')), always_2d=True)\n",
    "        est, sr = sf.read(str(Path(estdir, 'source3' + '.wav')), always_2d=True)\n",
    "\n",
    "        ref = ref[:,0][None, ...]\n",
    "        est = est[None, ...]\n",
    "\n",
    "        SDR, ISR, SIR, SAR = museval.evaluate(ref, est, win=sr, hop=sr)\n",
    "        values = {\n",
    "                'track':estdir.name,\n",
    "                \"SDR\": median_nan(SDR[0]),\n",
    "                \"ISR\": median_nan(ISR[0]),\n",
    "                \"SIR\": median_nan(SIR[0]),\n",
    "                \"SAR\": median_nan(SAR[0])\n",
    "            }\n",
    "        result.loc[result.shape[0]] = values\n",
    "\n",
    "values = {\n",
    "        'track':'sum',\n",
    "        \"SDR\": result['SDR'].median(),\n",
    "        \"ISR\": result['ISR'].median(),\n",
    "        \"SIR\": result['SIR'].median(),\n",
    "        \"SAR\": result['SAR'].median()\n",
    "}\n",
    "result.loc[result.shape[0]] = values\n",
    "print(list((result.loc[result.shape[0] - 1])[1:]))\n",
    "result.to_csv(str(output_dir)+'.csv',index=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "svs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
